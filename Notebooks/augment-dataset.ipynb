{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12510604,"sourceType":"datasetVersion","datasetId":7896473}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install -U albumentations\n!pip install -U opencv-python-headless","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T14:58:27.812247Z","iopub.execute_input":"2025-09-03T14:58:27.812515Z","iopub.status.idle":"2025-09-03T14:58:41.892465Z","shell.execute_reply.started":"2025-09-03T14:58:27.812490Z","shell.execute_reply":"2025-09-03T14:58:41.891374Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"%%writefile augment_and_save.py\n\"\"\"\n==============================================================================\nAUGMENT_AND_SAVE.PY (v2 - CORRECTED)\n==============================================================================\nThis script performs offline data augmentation. It reads images from a source\ndirectory, applies a series of transformations, and saves the newly generated\nimages to an output directory, preserving the class folder structure.\n\nv2 FIXES:\n- Updated GaussNoise and CoarseDropout to use the modern Albumentations API,\n  resolving the UserWarning messages.\n\"\"\"\n\nimport os\nimport argparse\nimport numpy as np\nimport albumentations as A\nfrom pathlib import Path\nfrom PIL import Image\nfrom tqdm import tqdm\n\ndef get_augmentation_pipeline():\n    \"\"\"\n    Defines and returns the Albumentations augmentation pipeline.\n    This pipeline uses the modern, correct syntax.\n    \"\"\"\n    print(\"Defining corrected augmentation pipeline...\")\n    return A.Compose([\n        A.HorizontalFlip(p=0.5),\n        A.Rotate(limit=30, p=0.7),\n        A.Affine(scale=(0.85, 1.15), translate_percent=(-0.1, 0.1), rotate=(-25, 25), shear=(-10, 10), p=0.6),\n        A.GaussianBlur(blur_limit=(3, 7), p=0.3),\n        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.7),\n        \n        # CORRECTED: Uses the correct `var_limit` argument recognized by modern versions.\n        A.GaussNoise(p=0.4),\n        \n        A.Sharpen(p=0.2),\n        A.CLAHE(p=0.3),\n        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),\n        \n        # CORRECTED: These are the correct arguments for CoarseDropout in recent versions.\n        A.CoarseDropout(\n            p=0.3\n        ),\n    ])\n\ndef augment_and_save(source_dir, output_dir, num_augmentations):\n    \"\"\"\n    Finds all images in the source directory, applies augmentations,\n    and saves them to the output directory.\n    \"\"\"\n    source_path = Path(source_dir)\n    output_path = Path(output_dir)\n\n    if not source_path.exists():\n        print(f\"Error: Source directory '{source_path}' does not exist.\")\n        return\n\n    transform = get_augmentation_pipeline()\n\n    image_paths = list(source_path.glob(\"**/*.jpg\")) + \\\n                  list(source_path.glob(\"**/*.jpeg\")) + \\\n                  list(source_path.glob(\"**/*.png\"))\n\n    print(f\"\\nFound {len(image_paths)} original images in '{source_path}'.\")\n    print(f\"Generating {num_augmentations} augmented versions for each image...\")\n\n    for image_path in tqdm(image_paths, desc=\"Augmenting Images\"):\n        try:\n            original_image = Image.open(image_path).convert(\"RGB\")\n            image_np = np.array(original_image)\n\n            class_name = image_path.parent.name\n            output_class_path = output_path / class_name\n            output_class_path.mkdir(parents=True, exist_ok=True)\n\n            original_filename = image_path.name\n            original_dest_path = output_class_path / original_filename\n            if not original_dest_path.exists():\n                original_image.save(original_dest_path)\n\n            for i in range(num_augmentations):\n                augmented = transform(image=image_np)['image']\n                aug_image_pil = Image.fromarray(augmented)\n                original_stem = image_path.stem\n                original_suffix = image_path.suffix\n                new_filename = f\"{original_stem}_aug_{i+1}{original_suffix}\"\n                aug_image_pil.save(output_class_path / new_filename)\n\n        except Exception as e:\n            print(f\"\\nWarning: Could not process or augment image {image_path}. Error: {e}\")\n\n    print(\"\\n✅ Augmentation process complete!\")\n    print(f\"New dataset saved at: '{output_path}'\")\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Offline Image Augmentation Script\")\n    parser.add_argument(\"--source-dir\", type=str, required=True, help=\"Path to original images.\")\n    parser.add_argument(\"--output-dir\", type=str, required=True, help=\"Path to save augmented dataset.\")\n    parser.add_argument(\"--num-augmentations\", type=int, default=10, help=\"Number of augmented versions per image.\")\n    args = parser.parse_args()\n    augment_and_save(args.source_dir, args.output_dir, args.num_augmentations)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-03T14:58:41.894059Z","iopub.execute_input":"2025-09-03T14:58:41.894310Z","iopub.status.idle":"2025-09-03T14:58:41.902431Z","shell.execute_reply.started":"2025-09-03T14:58:41.894287Z","shell.execute_reply":"2025-09-03T14:58:41.901685Z"}},"outputs":[{"name":"stdout","text":"Writing augment_and_save.py\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!python augment_and_save.py \\\n    --source-dir \"/kaggle/input/maize-dataset/\" \\\n    --output-dir \"/kaggle/working/augmented_maize_dataset/\" \\\n    --num-augmentations 10","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T14:58:41.903112Z","iopub.execute_input":"2025-09-03T14:58:41.903372Z","iopub.status.idle":"2025-09-03T15:03:37.704706Z","shell.execute_reply.started":"2025-09-03T14:58:41.903355Z","shell.execute_reply":"2025-09-03T15:03:37.703676Z"}},"outputs":[{"name":"stdout","text":"Defining corrected augmentation pipeline...\n\nFound 176 original images in '/kaggle/input/maize-dataset'.\nGenerating 10 augmented versions for each image...\nAugmenting Images: 100%|██████████████████████| 176/176 [04:48<00:00,  1.64s/it]\n\n✅ Augmentation process complete!\nNew dataset saved at: '/kaggle/working/augmented_maize_dataset'\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from pathlib import Path\n\noutput_dataset_path = Path(\"/kaggle/working/augmented_maize_dataset/\")\n\n# Count total images\ntotal_new_images = len(list(output_dataset_path.glob(\"**/*.jpg\")))\nprint(f\"Total images in the new dataset: {total_new_images}\")\n\n# Count images in a specific class\nhealthy_path = output_dataset_path / \"maize_healthy\"\nnum_healthy = len(list(healthy_path.glob(\"*.jpg\")))\nprint(f\"Total images in 'maize_healthy': {num_healthy}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T15:03:37.706512Z","iopub.execute_input":"2025-09-03T15:03:37.706698Z","iopub.status.idle":"2025-09-03T15:03:37.723954Z","shell.execute_reply.started":"2025-09-03T15:03:37.706679Z","shell.execute_reply":"2025-09-03T15:03:37.723444Z"}},"outputs":[{"name":"stdout","text":"Total images in the new dataset: 1936\nTotal images in 'maize_healthy': 1474\n","output_type":"stream"}],"execution_count":4}]}